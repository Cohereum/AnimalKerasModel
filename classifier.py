import numpy as np
import os
import cv2
import json

import keras.backend as K
from keras import optimizers
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.regularizers import l2
from keras.losses import categorical_crossentropy
from keras.losses import binary_crossentropy
from keras.layers import (
	Dense,
	Conv2D,
	BatchNormalization,
	Dropout,
	Activation,
	MaxPooling2D,
	AveragePooling2D,
	Flatten
	)

epochs = 500
TRAIN_DIR = './data/'
IMG_SIZE = (64, 64)
LABELS = [
    'raccoon',
    'other'
]


def label_img(img):
	one_hot_label = [0]*len(LABELS)
	for index, label in enumerate(LABELS):
		if img.startswith(label):
			one_hot_label[index] = 1
			return one_hot_label

	assert 1 in one_hot_label


def create_data():
    training_data = []

    for img in os.listdir(TRAIN_DIR):
        label = label_img(img)
        path = os.path.join(TRAIN_DIR, img)
        img = cv2.imread(path)
        img = cv2.resize(img, (IMG_SIZE[0], IMG_SIZE[1]))
        training_data.append([np.array(img), label])

    return training_data

data = create_data()

split = int(len(data) * 0.2)
train = data[:-split]
test = data[-split:]

x_train = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE[0], IMG_SIZE[1], 3)
y_train = np.array([i[1] for i in train])

x_test = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE[0], IMG_SIZE[1], 3)
y_test = np.array([i[1] for i in test])

input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3)
classes = len(LABELS)

model = Sequential()

model.add(Conv2D(filters=32, activation='relu', kernel_size=3, padding='same', kernel_regularizer=l2(1e-4), input_shape=input_shape))
model.add(BatchNormalization())
model.add(Conv2D(filters=32, activation='relu', kernel_size=3, padding='same', kernel_regularizer=l2(1e-4)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.5))

model.add(Conv2D(filters=64, activation='relu', kernel_size=3, padding='same', kernel_regularizer=l2(1e-4)))
model.add(BatchNormalization())
model.add(Conv2D(filters=64, activation='relu', kernel_size=3, padding='same', kernel_regularizer=l2(1e-4)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.5))

model.add(Conv2D(filters=128, activation='relu', kernel_size=3, padding='same', kernel_regularizer=l2(1e-4)))
model.add(BatchNormalization())
model.add(Conv2D(filters=128, activation='relu', kernel_size=3, padding='same', kernel_regularizer=l2(1e-4)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.5))

model.add(Flatten())
model.add(Dense(units=classes, activation='softmax'))

model.compile(
	loss=categorical_crossentropy,
	optimizer="adam",
	metrics=['accuracy'])


x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255

datagen = ImageDataGenerator(
        featurewise_center=False,
        samplewise_center=False,
        featurewise_std_normalization=False,
        samplewise_std_normalization=False,
        zca_whitening=False,
        zca_epsilon=1e-06,
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.1,
        zoom_range=0.1,
        channel_shift_range=0.,
        fill_mode='nearest',
        cval=0.,
        horizontal_flip=True,
        vertical_flip=False,
        rescale=None,
        preprocessing_function=None,
        data_format=None,
        validation_split=0.0)

try:
	datagen.fit(x_train)

	# Fit the model on the batches generated by datagen.flow().
	model.fit_generator(datagen.flow(x_train, y_train, batch_size=128),
		epochs=epochs,
		validation_data=(x_test, y_test))
except:
	print('Training aborted. Something went wrong.')

model_json = model.to_json()
with open("saved_model/model.json", "w") as json_file:
    json_file.write(json.dumps(json.loads(model_json), indent=4))

model.save_weights('saved_model/model_weights.h5')

final_acc = model.evaluate(x_test, y_test, verbose=1)
print(final_acc)
